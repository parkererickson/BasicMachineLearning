{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "#tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#Model Weights\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#Construct Model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "#Cost Function\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred)))\n",
    "\n",
    "#Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#Init Variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=42.43927512255579159727858495898544788360595703125\n",
      "Epoch: 0002 cost=31.907869432622764094276135438121855258941650390625\n",
      "Epoch: 0003 cost=30.389599409970347920761923887766897678375244140625\n",
      "Epoch: 0004 cost=29.6551393422213322992320172488689422607421875\n",
      "Epoch: 0005 cost=29.16829787254335570878538419492542743682861328125\n",
      "Epoch: 0006 cost=28.903693559820002434435082250274717807769775390625\n",
      "Epoch: 0007 cost=28.84036548787896236945016426034271717071533203125\n",
      "Epoch: 0008 cost=28.343892312483347950546885840594768524169921875\n",
      "Epoch: 0009 cost=28.08403538617221073536711628548800945281982421875\n",
      "Epoch: 0010 cost=27.88969466556203968821137095801532268524169921875\n",
      "Epoch: 0011 cost=27.775990919633358089413377456367015838623046875\n",
      "Epoch: 0012 cost=27.574940521933815062993744504638016223907470703125\n",
      "Epoch: 0013 cost=27.279346153085878512456474709324538707733154296875\n",
      "Epoch: 0014 cost=27.201154166134937639753843541257083415985107421875\n",
      "Epoch: 0015 cost=27.064806956377889690656957100145518779754638671875\n",
      "Epoch: 0016 cost=27.113697400526579173174468451179563999176025390625\n",
      "Epoch: 0017 cost=27.064945554733260024704577517695724964141845703125\n",
      "Epoch: 0018 cost=26.891795278028997273622735519893467426300048828125\n",
      "Epoch: 0019 cost=26.871389910091021846483272383920848369598388671875\n",
      "Epoch: 0020 cost=27.0735890821976994402575655840337276458740234375\n",
      "Epoch: 0021 cost=26.922680162949962578977647353895008563995361328125\n",
      "Epoch: 0022 cost=26.688101178082543896152856177650392055511474609375\n",
      "Epoch: 0023 cost=26.714560465379197040647341054864227771759033203125\n",
      "Epoch: 0024 cost=26.689731185219503828420783975161612033843994140625\n",
      "Epoch: 0025 cost=26.41308453993365645828816923312842845916748046875\n",
      "Epoch: 0026 cost=26.4923977921225883847000659443438053131103515625\n",
      "Epoch: 0027 cost=26.4304772394353477693584864027798175811767578125\n",
      "Epoch: 0028 cost=26.50835148637944627125762053765356540679931640625\n",
      "Epoch: 0029 cost=26.431417914303889205029918230138719081878662109375\n",
      "Epoch: 0030 cost=26.29852141033516232937472523190081119537353515625\n",
      "Epoch: 0031 cost=26.41348502592608582517641480080783367156982421875\n",
      "Epoch: 0032 cost=26.137101240158099102472988306544721126556396484375\n",
      "Epoch: 0033 cost=26.14595413468101270382248912937939167022705078125\n",
      "Epoch: 0034 cost=26.141238635670038803482384537346661090850830078125\n",
      "Epoch: 0035 cost=26.0248517036437903016121708787977695465087890625\n",
      "Epoch: 0036 cost=25.997850366072210448464829823933541774749755859375\n",
      "Epoch: 0037 cost=26.083454455462376841978766606189310550689697265625\n",
      "Epoch: 0038 cost=26.010835883400662993381047272123396396636962890625\n",
      "Epoch: 0039 cost=26.038189149336357530728491838090121746063232421875\n",
      "Epoch: 0040 cost=25.881290529424493485066705034114420413970947265625\n",
      "Epoch: 0041 cost=25.8393714835427346088181366212666034698486328125\n",
      "Epoch: 0042 cost=25.90159953204067022625167737714946269989013671875\n",
      "Epoch: 0043 cost=25.790072110782961800623525050468742847442626953125\n",
      "Epoch: 0044 cost=25.772976398468035341693394002504646778106689453125\n",
      "Epoch: 0045 cost=25.763497557206608945534753729589283466339111328125\n",
      "Epoch: 0046 cost=25.707119271538470428595246630720794200897216796875\n",
      "Epoch: 0047 cost=25.801236630353063361553722643293440341949462890625\n",
      "Epoch: 0048 cost=25.6300927318226285933633334934711456298828125\n",
      "Epoch: 0049 cost=25.815985358845093600166364922188222408294677734375\n",
      "Epoch: 0050 cost=25.702473991567440947392242378555238246917724609375\n",
      "Epoch: 0051 cost=25.84434825723821660403700661845505237579345703125\n",
      "Epoch: 0052 cost=25.769186572161611792353141936473548412322998046875\n",
      "Epoch: 0053 cost=25.703483280702076996249161311425268650054931640625\n"
     ]
    }
   ],
   "source": [
    "#Start Training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs, \n",
    "                                                          y: batch_ys})\n",
    "            avg_cost += c/total_batch\n",
    "            \n",
    "        if  (epoch+1) % display_step ==0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\" \"{:.95}\".format(avg_cost)\n",
    "    \n",
    "    print \"Optimization Finished!\"\n",
    "    \n",
    "    #Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    #Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
